## Tensorrt-多流模式

Tensorrt推理后端通过创建多个上下文和stream支持多流模式，可以提高GPU使用率以及推理性能，相应也会增加GPU显存占用。

## 使用

见[tensorrt inferer说明](7_InternalInferer.md#tensorrt-inferer)。

## 性能提升

例如使用[resnet-50-trt](https://github.com/NetEase-Media/grps_examples/tree/master/cpp_examples/resnet-50-trt)
做测试，结果如下：

环境：

```
镜像：registry.cn-hangzhou.aliyuncs.com/opengrps/grps_gpu:grps1.1.0_cuda11.3_cudnn8.2_trt7.2.3_py3.8
GPU：1080Ti
```

Latency:

| stream个数 \ latency(ms) \ 并发 | 1      | 2       | 4        | 8       | 16       | 32      |
|-----------------------------|--------|---------|----------|---------|----------|---------|
| 1                           | 40.2   | 33.4    | 62.9     | 127.93  | 258.71   | 519.57  |
| 2                           | 40.14	 | 33.15	  | 50.96	   | 100.9	  | 206.77	  | 416.78  |
| 同比                          | -0.15% | -0.75%	 | -18.98%	 | -21.13% | -20.08%	 | -19.78% |

显存:

| stream个数 \ GPU显存(MB) \ 并发 | 1     | 2     | 4     | 8     | 16    | 32   |
|---------------------------|-------|-------|-------|-------|-------|------|
| 1                         | 848   | 848   | 848   | 848   | 848   | 848  |
| 2                         | 1454	 | 1454	 | 1454	 | 1454	 | 1454	 | 1454 |

GPU使用率:

| stream个数 \ GPU使用率(%) \ 并发 | 1   | 2   | 4   | 8   | 16  | 32 |
|---------------------------|-----|-----|-----|-----|-----|----|
| 1                         | 57  | 85  | 97  | 96  | 96  | 96 |
| 2                         | 57	 | 85	 | 98	 | 99	 | 98	 | 99 |